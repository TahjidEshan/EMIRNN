{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T10:26:15.348000Z",
     "start_time": "2018-12-27T10:26:13.153583Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#This code is for adaptive GPU usage\n",
    "import keras.backend as K\n",
    "cfg = K.tf.ConfigProto()\n",
    "cfg.gpu_options.allow_growth = True\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T10:26:16.212784Z",
     "start_time": "2018-12-27T10:26:15.962557Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN, GRU,LSTM, Dense, Input\n",
    "from keras.models import Model\n",
    "import keras.optimizers as O\n",
    "import keras.losses as L\n",
    "import keras.activations as A\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from numpy.random import seed\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display \n",
    "pd.options.display.max_columns = None\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T10:26:16.589293Z",
     "start_time": "2018-12-27T10:26:16.580639Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model_lstm(num_timesteps = 128, num_input = 9, num_hidden = 128, num_classes = 3):\n",
    "    '''\n",
    "        Function that builds and returns a basline LSTM model.\n",
    "        Architecture : \n",
    "        Layer 1 : Input Layer.\n",
    "        Layer 2 : LSTM Layer.\n",
    "        Layer 3 : Dense layer with num_classes number of nodes.\n",
    "        \n",
    "        I/P:\n",
    "            num_timesteps : no. of timesteps that are present in the dataset.\n",
    "            num_input : no. of input signals for the Input layer.\n",
    "            num_hidden : no. of hidden units for the LSTM layer.\n",
    "            num_classes : no. of output classes, for the dense layer.\n",
    "            \n",
    "        Returns : \n",
    "            Constructed model.\n",
    "    '''\n",
    "    ip = Input(shape = (num_timesteps, num_input))\n",
    "    x_ip = LSTM(num_hidden)(ip)\n",
    "    x_op = Dense(num_classes, activation='softmax')(x_ip)\n",
    "    \n",
    "    model = Model(inputs = [ip], outputs = [x_op])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(optimizer = O.Adam(), loss = L.categorical_crossentropy, metrics = ['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_rnn(num_timesteps = 128, num_input = 9, num_hidden = 128, num_classes = 3):\n",
    "    '''\n",
    "        Function that builds and returns a basline LSTM model.\n",
    "        Architecture : \n",
    "        Layer 1 : Input Layer.\n",
    "        Layer 2 : Simple RNN Layer.\n",
    "        Layer 3 : Dense layer with num_classes number of nodes.\n",
    "        \n",
    "        I/P:\n",
    "            num_timesteps : no. of timesteps that are present in the dataset.\n",
    "            num_input : no. of input signals for the Input layer.\n",
    "            num_hidden : no. of hidden units for the LSTM layer.\n",
    "            num_classes : no. of output classes, for the dense layer.\n",
    "            \n",
    "        Returns : \n",
    "            Constructed model.\n",
    "    '''\n",
    "    ip = Input(shape = (num_timesteps, num_input))\n",
    "    x_ip = SimpleRNN(num_hidden)(ip)\n",
    "    x_op = Dense(num_classes, activation='softmax')(x_ip)\n",
    "    \n",
    "    model = Model(inputs = [ip], outputs = [x_op])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(optimizer = O.Adam(), loss = L.categorical_crossentropy, metrics = ['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_gru(num_timesteps = 128, num_input = 9, num_hidden = 128, num_classes = 3):\n",
    "    '''\n",
    "        Function that builds and returns a basline LSTM model.\n",
    "        Architecture : \n",
    "        Layer 1 : Input Layer.\n",
    "        Layer 2 : GRU Layer.\n",
    "        Layer 3 : Dense layer with num_classes number of nodes.\n",
    "        \n",
    "        I/P:\n",
    "            num_timesteps : no. of timesteps that are present in the dataset.\n",
    "            num_input : no. of input signals for the Input layer.\n",
    "            num_hidden : no. of hidden units for the LSTM layer.\n",
    "            num_classes : no. of output classes, for the dense layer.\n",
    "            \n",
    "        Returns : \n",
    "            Constructed model.\n",
    "    '''\n",
    "    ip = Input(shape = (num_timesteps, num_input))\n",
    "    x_ip = GRU(num_hidden)(ip)\n",
    "    x_op = Dense(num_classes, activation='softmax')(x_ip)\n",
    "    \n",
    "    model1 = Model(inputs = [ip], outputs = [x_op])\n",
    "    \n",
    "    model1.summary()\n",
    "    \n",
    "    model1.compile(optimizer = O.Adam(), loss = L.categorical_crossentropy, metrics = ['acc'])\n",
    "    \n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T09:26:09.654778Z",
     "start_time": "2018-12-27T09:19:47.750590Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(path = '/home/iot/Documents/dataset_fog_release/dataset/RAW1/'):\n",
    "    '''\n",
    "        Function that takes in the path of a dataset and reads and returns the train, validation and test\n",
    "        splits.\n",
    "    '''\n",
    "    x_train, y_train = np.load(path + 'x_train.npy'), np.load(path + 'y_train.npy')\n",
    "    x_test, y_test = np.load(path + 'x_test.npy'), np.load(path + 'y_test.npy')\n",
    "    x_val, y_val = np.load(path + 'x_val.npy'), np.load(path + 'y_val.npy')\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, x_val, y_val\n",
    "\n",
    "path = \"/home/iot/Documents/dataset_fog_release/dataset/RAW1/\"\n",
    "x_train, y_train, x_test, y_test, x_val, y_val = load_data(path)\n",
    "\n",
    "class_W = {0: 1.0,\n",
    "           1: 1.0,\n",
    "           2: 2.96}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape[0]+x_test.shape[0]+x_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T09:26:09.654778Z",
     "start_time": "2018-12-27T09:19:47.750590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 9)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               70656     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 71,043\n",
      "Trainable params: 71,043\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 463 samples, validate on 52 samples\n",
      "Epoch 1/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.9815 - acc: 0.5875 - val_loss: 0.8175 - val_acc: 0.5769\n",
      "Epoch 2/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.6847 - acc: 0.6868 - val_loss: 0.5647 - val_acc: 0.7692\n",
      "Epoch 3/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.6000 - acc: 0.7106 - val_loss: 0.5303 - val_acc: 0.7692\n",
      "Epoch 4/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.5277 - acc: 0.7365 - val_loss: 0.5066 - val_acc: 0.7308\n",
      "Epoch 5/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.5440 - acc: 0.7559 - val_loss: 0.5404 - val_acc: 0.6538\n",
      "Epoch 6/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.5482 - acc: 0.7732 - val_loss: 0.5077 - val_acc: 0.7885\n",
      "Epoch 7/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.5066 - acc: 0.7819 - val_loss: 0.4298 - val_acc: 0.7308\n",
      "Epoch 8/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.4747 - acc: 0.8099 - val_loss: 0.4291 - val_acc: 0.7500\n",
      "Epoch 9/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.4235 - acc: 0.8186 - val_loss: 0.4270 - val_acc: 0.7500\n",
      "Epoch 10/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.4350 - acc: 0.8272 - val_loss: 0.4210 - val_acc: 0.8269\n",
      "Epoch 11/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.4509 - acc: 0.8164 - val_loss: 0.3841 - val_acc: 0.8269\n",
      "Epoch 12/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.4820 - acc: 0.7624 - val_loss: 0.5053 - val_acc: 0.7500\n",
      "Epoch 13/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.4649 - acc: 0.8078 - val_loss: 0.4006 - val_acc: 0.7885\n",
      "Epoch 14/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.3933 - acc: 0.8272 - val_loss: 0.4107 - val_acc: 0.7692\n",
      "Epoch 15/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.3673 - acc: 0.8423 - val_loss: 0.3637 - val_acc: 0.7885\n",
      "Epoch 16/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.3996 - acc: 0.8315 - val_loss: 0.3341 - val_acc: 0.8654\n",
      "Epoch 17/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.3923 - acc: 0.8380 - val_loss: 0.3239 - val_acc: 0.8462\n",
      "Epoch 18/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.3707 - acc: 0.8510 - val_loss: 0.3889 - val_acc: 0.8462\n",
      "Epoch 19/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.3830 - acc: 0.8488 - val_loss: 0.3860 - val_acc: 0.8462\n",
      "Epoch 20/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.3430 - acc: 0.8639 - val_loss: 0.3052 - val_acc: 0.8846\n",
      "Epoch 21/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.3557 - acc: 0.8402 - val_loss: 0.3767 - val_acc: 0.8269\n",
      "Epoch 22/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.3321 - acc: 0.8639 - val_loss: 0.3336 - val_acc: 0.8269\n",
      "Epoch 23/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.3144 - acc: 0.8704 - val_loss: 0.3669 - val_acc: 0.8269\n",
      "Epoch 24/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.4001 - acc: 0.8423 - val_loss: 0.4535 - val_acc: 0.8269\n",
      "Epoch 25/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.3721 - acc: 0.8467 - val_loss: 0.3763 - val_acc: 0.8077\n",
      "Epoch 26/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.3733 - acc: 0.8337 - val_loss: 0.3981 - val_acc: 0.8462\n",
      "Epoch 27/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.3375 - acc: 0.8639 - val_loss: 0.3553 - val_acc: 0.8462\n",
      "Epoch 28/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.4691 - acc: 0.8553 - val_loss: 0.4060 - val_acc: 0.8269\n",
      "Epoch 29/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.3549 - acc: 0.8553 - val_loss: 0.3987 - val_acc: 0.8077\n",
      "Epoch 30/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.3317 - acc: 0.8812 - val_loss: 0.3473 - val_acc: 0.9038\n",
      "Epoch 31/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.3084 - acc: 0.8726 - val_loss: 0.3269 - val_acc: 0.8654\n",
      "Epoch 32/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.3584 - acc: 0.8467 - val_loss: 0.4365 - val_acc: 0.8077\n",
      "Epoch 33/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.3186 - acc: 0.8812 - val_loss: 0.3522 - val_acc: 0.8462\n",
      "Epoch 34/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.2835 - acc: 0.8855 - val_loss: 0.3289 - val_acc: 0.8846\n",
      "Epoch 35/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.3137 - acc: 0.8661 - val_loss: 0.6456 - val_acc: 0.7308\n",
      "Epoch 36/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.3158 - acc: 0.8769 - val_loss: 0.4679 - val_acc: 0.7885\n",
      "Epoch 37/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.3055 - acc: 0.8920 - val_loss: 0.3821 - val_acc: 0.8462\n",
      "Epoch 38/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.2953 - acc: 0.8855 - val_loss: 0.3431 - val_acc: 0.8654\n",
      "Epoch 39/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.2791 - acc: 0.8963 - val_loss: 0.3336 - val_acc: 0.8846\n",
      "Epoch 40/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.2502 - acc: 0.9071 - val_loss: 0.3123 - val_acc: 0.8846\n",
      "Epoch 41/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.2404 - acc: 0.9071 - val_loss: 0.2937 - val_acc: 0.8654\n",
      "Epoch 42/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.2685 - acc: 0.8834 - val_loss: 0.3874 - val_acc: 0.8462\n",
      "Epoch 43/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.2560 - acc: 0.9050 - val_loss: 0.3783 - val_acc: 0.8269\n",
      "Epoch 44/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.2879 - acc: 0.8834 - val_loss: 0.3469 - val_acc: 0.8462\n",
      "Epoch 45/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.3085 - acc: 0.8855 - val_loss: 0.3965 - val_acc: 0.8654\n",
      "Epoch 46/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.2504 - acc: 0.9028 - val_loss: 0.3617 - val_acc: 0.8654\n",
      "Epoch 47/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.3016 - acc: 0.8747 - val_loss: 0.2920 - val_acc: 0.9038\n",
      "Epoch 48/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.2882 - acc: 0.8834 - val_loss: 0.3491 - val_acc: 0.8654\n",
      "Epoch 49/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.2927 - acc: 0.8877 - val_loss: 0.3547 - val_acc: 0.8269\n",
      "Epoch 50/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.2833 - acc: 0.9028 - val_loss: 0.3550 - val_acc: 0.9038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99e002bc88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LSTM\n",
    "model = build_model_lstm(num_timesteps = x_train.shape[1], num_input = x_train.shape[-1], num_hidden = 128, num_classes = y_train.shape[-1])\n",
    "model.fit(x_train,y_train,epochs=50,batch_size=32,validation_data=[x_val,y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 128, 9)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 128)               52992     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 53,379\n",
      "Trainable params: 53,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 463 samples, validate on 221 samples\n",
      "Epoch 1/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 1.0357 - acc: 0.5097 - val_loss: 0.9145 - val_acc: 0.6244\n",
      "Epoch 2/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.8682 - acc: 0.6263 - val_loss: 0.7946 - val_acc: 0.6516\n",
      "Epoch 3/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.7458 - acc: 0.6609 - val_loss: 0.8013 - val_acc: 0.6606\n",
      "Epoch 4/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.6978 - acc: 0.6847 - val_loss: 0.6731 - val_acc: 0.6697\n",
      "Epoch 5/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.5931 - acc: 0.7430 - val_loss: 0.6444 - val_acc: 0.7104\n",
      "Epoch 6/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.5626 - acc: 0.7365 - val_loss: 0.6062 - val_acc: 0.7014\n",
      "Epoch 7/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.5378 - acc: 0.7495 - val_loss: 0.6209 - val_acc: 0.7195\n",
      "Epoch 8/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.5455 - acc: 0.7689 - val_loss: 0.6518 - val_acc: 0.7149\n",
      "Epoch 9/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.5240 - acc: 0.7862 - val_loss: 0.6071 - val_acc: 0.7285\n",
      "Epoch 10/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.4995 - acc: 0.8099 - val_loss: 0.5987 - val_acc: 0.7195\n",
      "Epoch 11/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.5103 - acc: 0.7689 - val_loss: 0.6122 - val_acc: 0.7014\n",
      "Epoch 12/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.4841 - acc: 0.7754 - val_loss: 0.7331 - val_acc: 0.7240\n",
      "Epoch 13/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.5395 - acc: 0.7819 - val_loss: 0.8811 - val_acc: 0.6290\n",
      "Epoch 14/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.5460 - acc: 0.7667 - val_loss: 0.6835 - val_acc: 0.7330\n",
      "Epoch 15/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.4825 - acc: 0.8035 - val_loss: 0.6864 - val_acc: 0.6652\n",
      "Epoch 16/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.4628 - acc: 0.8035 - val_loss: 0.6318 - val_acc: 0.7149\n",
      "Epoch 17/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.4313 - acc: 0.8272 - val_loss: 0.6028 - val_acc: 0.7376\n",
      "Epoch 18/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.4159 - acc: 0.8402 - val_loss: 0.5991 - val_acc: 0.7511\n",
      "Epoch 19/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.3964 - acc: 0.8272 - val_loss: 0.5634 - val_acc: 0.7602\n",
      "Epoch 20/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.3799 - acc: 0.8402 - val_loss: 0.5195 - val_acc: 0.7511\n",
      "Epoch 21/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.3431 - acc: 0.8661 - val_loss: 0.5049 - val_acc: 0.7511\n",
      "Epoch 22/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.3374 - acc: 0.8726 - val_loss: 0.4796 - val_acc: 0.7783\n",
      "Epoch 23/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.3143 - acc: 0.8704 - val_loss: 0.4286 - val_acc: 0.8009\n",
      "Epoch 24/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.2965 - acc: 0.8704 - val_loss: 0.4463 - val_acc: 0.7919\n",
      "Epoch 25/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.2860 - acc: 0.8877 - val_loss: 0.4270 - val_acc: 0.7919\n",
      "Epoch 26/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.3666 - acc: 0.8553 - val_loss: 0.5239 - val_acc: 0.7647\n",
      "Epoch 27/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.3699 - acc: 0.8618 - val_loss: 0.6172 - val_acc: 0.7285\n",
      "Epoch 28/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.2995 - acc: 0.8704 - val_loss: 0.4703 - val_acc: 0.7919\n",
      "Epoch 29/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.2745 - acc: 0.8920 - val_loss: 0.4927 - val_acc: 0.7783\n",
      "Epoch 30/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.2632 - acc: 0.8898 - val_loss: 0.4768 - val_acc: 0.8009\n",
      "Epoch 31/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.2471 - acc: 0.9006 - val_loss: 0.4627 - val_acc: 0.7828\n",
      "Epoch 32/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.2331 - acc: 0.9006 - val_loss: 0.5974 - val_acc: 0.7919\n",
      "Epoch 33/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.2542 - acc: 0.9006 - val_loss: 0.4895 - val_acc: 0.8054\n",
      "Epoch 34/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.2389 - acc: 0.9244 - val_loss: 0.5128 - val_acc: 0.8009\n",
      "Epoch 35/50\n",
      "463/463 [==============================] - 2s 4ms/step - loss: 0.2270 - acc: 0.9093 - val_loss: 0.4930 - val_acc: 0.8235\n",
      "Epoch 36/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.1929 - acc: 0.9244 - val_loss: 0.5322 - val_acc: 0.8145\n",
      "Epoch 37/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.1736 - acc: 0.9287 - val_loss: 0.5969 - val_acc: 0.8009\n",
      "Epoch 38/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.1747 - acc: 0.9309 - val_loss: 0.5574 - val_acc: 0.8054\n",
      "Epoch 39/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.1904 - acc: 0.9222 - val_loss: 0.5623 - val_acc: 0.7557\n",
      "Epoch 40/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.1778 - acc: 0.9309 - val_loss: 0.5796 - val_acc: 0.7964\n",
      "Epoch 41/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.1541 - acc: 0.9395 - val_loss: 0.7027 - val_acc: 0.7783\n",
      "Epoch 42/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.1667 - acc: 0.9266 - val_loss: 0.6808 - val_acc: 0.7919\n",
      "Epoch 43/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.1575 - acc: 0.9395 - val_loss: 0.6389 - val_acc: 0.7919\n",
      "Epoch 44/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.1597 - acc: 0.9374 - val_loss: 0.5832 - val_acc: 0.8145\n",
      "Epoch 45/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.1348 - acc: 0.9546 - val_loss: 0.5442 - val_acc: 0.7964\n",
      "Epoch 46/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.1074 - acc: 0.9611 - val_loss: 0.5483 - val_acc: 0.8100\n",
      "Epoch 47/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.0886 - acc: 0.9719 - val_loss: 0.7077 - val_acc: 0.7919\n",
      "Epoch 48/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.0774 - acc: 0.9741 - val_loss: 0.8647 - val_acc: 0.7919\n",
      "Epoch 49/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.0693 - acc: 0.9741 - val_loss: 0.4973 - val_acc: 0.8145\n",
      "Epoch 50/50\n",
      "463/463 [==============================] - 2s 3ms/step - loss: 0.2198 - acc: 0.9114 - val_loss: 0.6613 - val_acc: 0.7964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99bb5272e8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## GRU \n",
    "model1 = build_model_gru(num_timesteps = x_train.shape[1], num_input = x_train.shape[-1], num_hidden = 128, num_classes = y_train.shape[-1])\n",
    "model1.fit(x_train,y_train,epochs=50,batch_size=32,validation_data=[x_test,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 128, 9)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 128)               17664     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 18,051\n",
      "Trainable params: 18,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 463 samples, validate on 52 samples\n",
      "Epoch 1/50\n",
      "463/463 [==============================] - 1s 2ms/step - loss: 0.9208 - acc: 0.5529 - val_loss: 0.8139 - val_acc: 0.5962\n",
      "Epoch 2/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.7973 - acc: 0.6674 - val_loss: 0.7935 - val_acc: 0.5962\n",
      "Epoch 3/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.7032 - acc: 0.7322 - val_loss: 0.8032 - val_acc: 0.6346\n",
      "Epoch 4/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.7208 - acc: 0.7084 - val_loss: 0.7553 - val_acc: 0.6731\n",
      "Epoch 5/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.6586 - acc: 0.7473 - val_loss: 0.7768 - val_acc: 0.6346\n",
      "Epoch 6/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.6166 - acc: 0.7538 - val_loss: 0.7213 - val_acc: 0.6923\n",
      "Epoch 7/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.5871 - acc: 0.7840 - val_loss: 0.7454 - val_acc: 0.6923\n",
      "Epoch 8/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.5641 - acc: 0.7927 - val_loss: 0.6502 - val_acc: 0.6731\n",
      "Epoch 9/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.4825 - acc: 0.8207 - val_loss: 0.6710 - val_acc: 0.6923\n",
      "Epoch 10/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.5564 - acc: 0.7624 - val_loss: 0.7868 - val_acc: 0.6346\n",
      "Epoch 11/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.5674 - acc: 0.7754 - val_loss: 0.6800 - val_acc: 0.6346\n",
      "Epoch 12/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.5776 - acc: 0.7689 - val_loss: 0.7119 - val_acc: 0.6538\n",
      "Epoch 13/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.6001 - acc: 0.7646 - val_loss: 0.9241 - val_acc: 0.6923\n",
      "Epoch 14/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.5569 - acc: 0.7732 - val_loss: 0.8664 - val_acc: 0.5577\n",
      "Epoch 15/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.7473 - acc: 0.6933 - val_loss: 0.8526 - val_acc: 0.5577\n",
      "Epoch 16/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.7767 - acc: 0.6566 - val_loss: 0.8843 - val_acc: 0.5962\n",
      "Epoch 17/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.7129 - acc: 0.6911 - val_loss: 0.8702 - val_acc: 0.5962\n",
      "Epoch 18/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.6682 - acc: 0.7516 - val_loss: 0.7920 - val_acc: 0.6346\n",
      "Epoch 19/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.5832 - acc: 0.7862 - val_loss: 0.7228 - val_acc: 0.7115\n",
      "Epoch 20/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.5360 - acc: 0.7948 - val_loss: 0.8008 - val_acc: 0.5962\n",
      "Epoch 21/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.5532 - acc: 0.7970 - val_loss: 0.7912 - val_acc: 0.6346\n",
      "Epoch 22/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.5591 - acc: 0.7970 - val_loss: 0.8531 - val_acc: 0.6154\n",
      "Epoch 23/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.6104 - acc: 0.7797 - val_loss: 0.7865 - val_acc: 0.6731\n",
      "Epoch 24/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.4930 - acc: 0.8337 - val_loss: 0.7355 - val_acc: 0.6731\n",
      "Epoch 25/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.5684 - acc: 0.8056 - val_loss: 0.8284 - val_acc: 0.5769\n",
      "Epoch 26/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.4926 - acc: 0.8186 - val_loss: 0.7408 - val_acc: 0.6731\n",
      "Epoch 27/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.5006 - acc: 0.8121 - val_loss: 0.8511 - val_acc: 0.6731\n",
      "Epoch 28/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.4449 - acc: 0.8445 - val_loss: 0.8203 - val_acc: 0.6538\n",
      "Epoch 29/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.5083 - acc: 0.8078 - val_loss: 0.8384 - val_acc: 0.5962\n",
      "Epoch 30/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.4773 - acc: 0.8380 - val_loss: 0.7915 - val_acc: 0.6538\n",
      "Epoch 31/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.4488 - acc: 0.8423 - val_loss: 0.8169 - val_acc: 0.6538\n",
      "Epoch 32/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.4768 - acc: 0.8337 - val_loss: 0.8710 - val_acc: 0.6346\n",
      "Epoch 33/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.4902 - acc: 0.7991 - val_loss: 0.7408 - val_acc: 0.6731\n",
      "Epoch 34/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.4512 - acc: 0.8359 - val_loss: 0.7342 - val_acc: 0.6538\n",
      "Epoch 35/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.4000 - acc: 0.8704 - val_loss: 0.7583 - val_acc: 0.6923\n",
      "Epoch 36/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.3613 - acc: 0.8790 - val_loss: 0.7748 - val_acc: 0.6923\n",
      "Epoch 37/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.3179 - acc: 0.8920 - val_loss: 0.8308 - val_acc: 0.6154\n",
      "Epoch 38/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.2987 - acc: 0.8985 - val_loss: 0.8197 - val_acc: 0.6731\n",
      "Epoch 39/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.3124 - acc: 0.8985 - val_loss: 0.7689 - val_acc: 0.6346\n",
      "Epoch 40/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.3185 - acc: 0.9028 - val_loss: 0.8485 - val_acc: 0.7115\n",
      "Epoch 41/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.2589 - acc: 0.9114 - val_loss: 0.8292 - val_acc: 0.6538\n",
      "Epoch 42/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.2805 - acc: 0.9136 - val_loss: 0.7698 - val_acc: 0.6731\n",
      "Epoch 43/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.3342 - acc: 0.8855 - val_loss: 0.8948 - val_acc: 0.6538\n",
      "Epoch 44/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.2927 - acc: 0.9071 - val_loss: 0.8514 - val_acc: 0.6923\n",
      "Epoch 45/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.2661 - acc: 0.9201 - val_loss: 0.9085 - val_acc: 0.6154\n",
      "Epoch 46/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.2608 - acc: 0.9050 - val_loss: 0.8064 - val_acc: 0.7308\n",
      "Epoch 47/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.2541 - acc: 0.9201 - val_loss: 0.8499 - val_acc: 0.6731\n",
      "Epoch 48/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.2967 - acc: 0.8790 - val_loss: 0.9971 - val_acc: 0.6538\n",
      "Epoch 49/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.2794 - acc: 0.9093 - val_loss: 0.8519 - val_acc: 0.6538\n",
      "Epoch 50/50\n",
      "463/463 [==============================] - 1s 1ms/step - loss: 0.2594 - acc: 0.9136 - val_loss: 0.7923 - val_acc: 0.6538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99b00d2b00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RNN\n",
    "model2 = build_model_rnn(num_timesteps = x_train.shape[1], num_input = x_train.shape[-1], num_hidden = 128, num_classes = y_train.shape[-1])\n",
    "model2.fit(x_train,y_train,epochs=50,batch_size=32,validation_data=[x_val,y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T09:26:09.654778Z",
     "start_time": "2018-12-27T09:19:47.750590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 793 ms, sys: 111 ms, total: 903 ms\n",
      "Wall time: 261 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Classification Accuracy :  0.8054298642533937\n"
     ]
    }
   ],
   "source": [
    "preds = np_utils.to_categorical(np.argmax(preds,axis=1))\n",
    "print (\"Final Classification Accuracy : \",accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T09:26:09.654778Z",
     "start_time": "2018-12-27T09:19:47.750590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 653 ms, sys: 54.9 ms, total: 708 ms\n",
      "Wall time: 295 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds1 = model1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Classification Accuracy :  0.7963800904977375\n"
     ]
    }
   ],
   "source": [
    "preds1 = np_utils.to_categorical(np.argmax(preds1,axis=1))\n",
    "print (\"Final Classification Accuracy : \",accuracy_score(y_test,preds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 340 ms, sys: 38.6 ms, total: 379 ms\n",
      "Wall time: 194 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds2 = model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T09:26:09.654778Z",
     "start_time": "2018-12-27T09:19:47.750590Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Classification Accuracy :  0.6244343891402715\n"
     ]
    }
   ],
   "source": [
    "preds2 = np_utils.to_categorical(np.argmax(preds2,axis=1))\n",
    "print (\"Final Classification Accuracy : \",accuracy_score(y_test,preds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T09:26:09.668370Z",
     "start_time": "2018-12-27T09:26:09.657949Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Classification Accuracy :  0.7782805429864253\n",
      "Final Classification Accuracy :  0.7782805429864253\n",
      "Final Classification Accuracy :  0.6561085972850679\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "os.chdir(\"/home/iot/Documents/\")\n",
    "model.save('baseline_lstm.h5')\n",
    "model1.save('baseline_gru.h5')\n",
    "model2.save('baseline_rnn.h5')# creates a HDF5 file 'baseline_lstm.h5' in Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "os.chdir(\"/home/iot/Documents/\")\n",
    "model = load_model('baseline_lstm.h5')\n",
    "model1 = load_model('baseline_gru.h5')\n",
    "model2 = load_model('baseline_rnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 315 ms, sys: 40.6 ms, total: 356 ms\n",
      "Wall time: 218 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = model.predict(x_test,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 379 ms, sys: 46.2 ms, total: 425 ms\n",
      "Wall time: 237 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds1 = model1.predict(x_test,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds2 = model1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = np_utils.to_categorical(np.argmax(preds,axis=1))\n",
    "# preds1 = np_utils.to_categorical(np.argmax(preds1,axis=1))\n",
    "# print (\"Final Classification Accuracy : \",accuracy_score(y_test,preds))\n",
    "# print (\"Final Classification Accuracy : \",accuracy_score(y_test,preds1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IOT - tf 1.0",
   "language": "python",
   "name": "envname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
